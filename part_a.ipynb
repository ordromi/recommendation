{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy import genfromtxt,savetxt,loadtxt\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7\n",
    "alpha = 0.07\n",
    "lamb_u = 0.15\n",
    "lamb_i = 0.01\n",
    "iterations = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "train_set = genfromtxt('Train.csv', delimiter=',')\n",
    "train_set = np.delete(train_set, (0), axis=0)\n",
    "valid_set = genfromtxt('Validation.csv', delimiter=',')\n",
    "valid_set = np.delete(valid_set, (0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "users_table = genfromtxt('Users Demographics.csv', delimiter=',')\n",
    "users_table = np.delete(users_table, (0), axis=0)\n",
    "users = users_table[:,0]\n",
    "movies_table = genfromtxt('Movies Metadata.csv', delimiter=',')\n",
    "movies_table = np.delete(movies_table, (0), axis=0)\n",
    "items = movies_table[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the biases\n",
    "# b_u = np.zeros(users.size) #user bias\n",
    "# b_i = np.zeros(items.size) #item bias\n",
    "b_u = loadtxt('bu.csv', delimiter=',')\n",
    "b_i = loadtxt('bi.csv', delimiter=',')\n",
    "\n",
    "\n",
    "b = np.mean(train_set[:,2]) #global bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_P_Q(k):\n",
    "    #initialize user(P) and item(Q) feature matrix\n",
    "#     P = np.array(np.random.uniform(0, 1, users.shape[0] * k).reshape(users.shape[0], k))\n",
    "#     Q = np.array(np.random.uniform(0, 1, items.shape[0] * k).reshape(k, items.shape[0]))\n",
    "    \n",
    "    P = loadtxt('p.csv', delimiter=',')\n",
    "    Q = loadtxt('q.csv', delimiter=',')\n",
    "    return P,Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(predictions, targets):\n",
    "    return sum(abs(targets - predictions))/ targets.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_squre(predictions, targets):\n",
    "    SSres = sum((targets - predictions)** 2)\n",
    "    SStotal = sum((targets - np.mean(targets))** 2)\n",
    "    return 1 - (SSres/SStotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_set,P,Q,alpha,lamb_u,lamb_i,iterations, valid_set):\n",
    "    flag = 0\n",
    "    rmse_old = 0 \n",
    "    RMSE = 0\n",
    "    for i in range(iterations) :\n",
    "        P,Q, prediction,b_u,b_i = SGD(train_set, P, Q, alpha, lamb_u,lamb_i)\n",
    "        targets = train_set[:,2]\n",
    "        RMSE_T = rmse(prediction,targets)\n",
    "        print(f\"iteration {i} : error in train is: {RMSE_T}\")\n",
    "        \n",
    "        #test for overfitting\n",
    "        p = predict(valid_set[:,[0,1]], P,Q,b_u,b_i)\n",
    "        targets = valid_set[:,2]\n",
    "        rmse_old = RMSE\n",
    "        RMSE =rmse(p,targets)\n",
    "        print(f\"iteration {i} : error in test is: {RMSE}\")\n",
    "        if RMSE > rmse_old and i>1 :\n",
    "            flag = flag + 1\n",
    "        if flag==2:\n",
    "            break\n",
    "        \n",
    "        #update alpha       \n",
    "        alpha = 0.9*alpha \n",
    "        \n",
    "    return P,Q,b_u,b_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(train_set, P, Q, alpha, lamb_u,lamb_i):\n",
    "    #stochastic gradient descent\n",
    "    predictions = []\n",
    "    for i,j,r in train_set:\n",
    "        error = 0\n",
    "        i = int(i)\n",
    "        j = int(j)\n",
    "        \n",
    "        prediction = b + b_u[i-1] + b_i[j-1] + P[i-1,:].dot(Q[:,j-1])\n",
    "        predictions.append(prediction)\n",
    "        error = (r - prediction)\n",
    "\n",
    "        #update biases\n",
    "        b_u[i-1] = b_u[i-1] + alpha*(error-lamb_u*b_u[i-1])\n",
    "        b_i[j-1] = b_i[j-1] + alpha*(error-lamb_i*b_i[j-1])\n",
    "        \n",
    "        #update matrrix\n",
    "        p_new = P[i-1,:] + alpha*(error*Q[:,j-1]-lamb_u*P[i-1,:])\n",
    "        q_new = Q[:,j-1] + alpha*(error*P[i-1,:]-lamb_i*Q[:,j-1])\n",
    "        P[i-1,:] = p_new[:]\n",
    "        Q[:,j-1] = q_new[:]       \n",
    "  \n",
    "    return P,Q,predictions,b_u,b_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, P,Q,b_u,b_i): \n",
    "# the function get a set of pairs (user,item), a model (P,Q,b_u,b_i) and predict the rating\n",
    "    predictions = []\n",
    "    for i,j in data: \n",
    "        i=int(i)\n",
    "        j=int(j)\n",
    "        prediction = b + b_u[i-1] + b_i[j-1] + P[i-1,:].dot(Q[:,j-1])\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(train_set,valid_set,ks,alphas,lambs_u,lambs_i,iterations):\n",
    "    score = np.inf\n",
    "    counter = 1\n",
    "    best = [0,0,0,0]\n",
    "    for k in ks:\n",
    "        for alpha in alphas:\n",
    "            for lamb_u in lambs_u:\n",
    "                for lumb_i in lambs_i:\n",
    "                    start_time = time.time()\n",
    "                    p,q = create_P_Q(k)\n",
    "                    print(f\"{counter}: params: [k:{k}, alpha:{alpha}, lamb_u:{lamb_u}, lamb_i:{lamb_i}]\")\n",
    "                    targets = valid_set[:,2]\n",
    "                    p,q,b_u,b_i = train(train_set,p,q,alpha,lamb_u,lamb_i,iterations,valid_set)\n",
    "                    predictions = predict(valid_set[:,[0,1]],p,q,b_u,b_i)\n",
    "                    RMSE = rmse(predictions,targets)\n",
    "                    if RMSE < score:\n",
    "                        score = RMSE\n",
    "                        best = [k,alpha,lamb_u,lamb_i]\n",
    "                        savetxt('bi.csv', b_i, delimiter=',') #save tha best model\n",
    "                        savetxt('bu.csv', b_u, delimiter=',') #save tha best model\n",
    "                        savetxt('p.csv', p, delimiter=',') #save tha best model\n",
    "                        savetxt('q.csv', q, delimiter=',') #save tha best model\n",
    "\n",
    "                    print(f\"Best params: {best}, with rmse = {score}\\n\")\n",
    "                    counter += 1\n",
    "    return best,RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params,rmse = grid_search(train_set,valid_set,ks,alphas,lambs_u,lambs_i,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6965028040077988\n",
      "0.8955580061590693\n",
      "0.35500416783787747\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "\n",
    "# P,Q=create_P_Q(k)\n",
    "# P,Q,b_u,b_i = train(train_set,P,Q,alpha,lamb_u,lamb_i,iterations, valid_set)\n",
    "\n",
    "prediction = predict(valid_set[:,[0,1]], P,Q,b_u,b_i)\n",
    "targets = valid_set[:,2]\n",
    "\n",
    "#calc RMSE,MAE,R^2\n",
    "MAE = mae(prediction,targets)\n",
    "RMSE =rmse(prediction,targets)\n",
    "R_SQURED = r_squre(prediction, targets)\n",
    "print(f\"RMSE: {RMSE} ,MAE: {MAE}, R_SQURED: {R_SQURED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks=[7]\n",
    "alphas = [0.07]\n",
    "lambs_u = [0.15]\n",
    "lambs_i = [0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Best params: [9, 0.05, 0.05], with rmse = 0.90765267392406\n",
    "# Best params: [9, 0.01, 0.05], with rmse = 0.9022141593766955\n",
    "# Best params: [9, 0.05, 0.1, 0.01], with rmse = 0.901681924572154\n",
    "# Best params: [7, 0.07, 0.1, 0.01], with rmse = 0.8968920688922477\n",
    "# Best params: [7, 0.09, 0.1, 0.01], with rmse = 0.8993324660380766\n",
    "# Best params: [8, 0.07, 0.1, 0.01], with rmse = 0.8989113015264709\n",
    "# Best params: [7, 0.07, 0.15, 0.01], with rmse = 0.8955580061590693"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'P' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-3d3645e4f9b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bi.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bu.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_u\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'P' is not defined"
     ]
    }
   ],
   "source": [
    "savetxt('bi.csv', b_i, delimiter=',')\n",
    "savetxt('bu.csv', b_u, delimiter=',')\n",
    "savetxt('p.csv', P, delimiter=',')\n",
    "savetxt('q.csv', Q, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
